---
categories:
- 开源
- 感悟
date: 2025-02-12T18:41:42+08:00
description: "DeepSeek 以开源的名义火出了圈，尽管目前在大模型这个新生事物的共识上，开源还处于争议和争执中，非营利机构OSI有全新的定义[1]，当然每家大模型也在定义，如llma，那么除了代码之外，还有哪些是开放的，可修改的等等都是模糊地带，笔者对这个新的领域并没有关注太多，毕竟原来的开放源代码还没有完全搞清楚。不过，借着如此出圈的事件，赶一个热度，也捋清一下大模型的打磨过程。"
keywords:
- Open Source
- Culture
- Reading
- News
tags:
- 每周精选
- 开源之道
title: "非官方观察：DeepSeek 的开放之路系列之一：arXiv  "
url: ""
authors:
- 「开源之道」·适兕 & 「开源之道」·窄廊
---

##  DeepSeek 发表在arXiv 上的几篇论文概述

在DeepSeek的网站[2]上，我们看到它的“研究一览，仅提供了几个GitHub上的仓库，每个仓库的README文件的顶部均有一个论文的链接，毫无例外，地址都是：**arXiv**。

### DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior[3]

最早发布的是一篇关于3d分层的文章,发表日期是2023年12月：论文提出了一种名为DreamCraft3D的分层3D内容生成方法。该方法利用一张2D参考图像引导两个阶段：首先通过视角依赖的扩散模型进行分数蒸馏采样，从而实现几何造型的一致性；其次引入“引导式分数蒸馏”（Bootstrapped Score Distillation）策略，通过训练个性化扩散模型DreamBooth对多视图渲染进行纹理增强。这种交替优化3D场景表示和扩散先验的方式，使得二者相互促进，显著提高了纹理质量，同时保持了全局视角的一致性，从而生成出既真实又具有高保真渲染效果的3D物体。

该篇论文，纯学术的研究，并未提及任何关于开源的内容。

### 首发：DeepSeek LLM：Scaling Open-Source Language Models with Longtermism[4]

这篇论文的摘要主要介绍了DeepSeek LLM项目，该项目致力于从长远视角推进开源大语言模型的发展。作者针对扩展定律在大语言模型扩展中的不一致结论进行了深入研究，并提出了一些独特发现，这些发现帮助他们在7B和67B两种常用配置下实现模型扩展。在预训练阶段，他们构建了一个目前包含2万亿tokens且持续扩展的大规模数据集，并结合监督微调（SFT）和直接偏好优化（DPO）技术，开发了DeepSeek Chat模型。实验评估显示，DeepSeek LLM 67B在多个基准测试中，尤其在代码、数学和推理任务上，表现优于LLaMA-2 70B；而DeepSeek LLM 67B Chat在开放式评测中则超越了GPT-3.5。

DeepSeek 论文中多次强调了开源的重要性和必要性，体现了其对开源生态的坚定信心和长远视角。作者认为开源不仅有助于推动大语言模型技术的发展，还能促进学术和工业界之间的信息共享与合作。具体来说，DeepSeek 的态度包括：

• 通过深入研究缩放规律，为构建和优化大模型提供科学依据，从而在开源领域树立长远发展的基础。

• 在项目中从零开始开发大语言模型，并尽可能公开训练数据、模型架构、超参数设置和实验细节，以便社区参考和复现。

• 利用庞大的预训练数据集（目前已达2万亿tokens）和先进的训练策略（如监督微调与直接偏好优化），展示了开源模型在代码、数学和推理等多方面能超越现有闭源模型的潜力。

总的来说，DeepSeek 表示他们致力于以开放、透明的方式推动大语言模型技术进步，并希望借此激发整个开源社区的协同创新，共同迈向人工智能的长期发展之路。

这篇文章可以说是奠定了DeepSeek 在大模型的方法论，可以说是一种宣言。过了一周，团队就又发表了另外一篇新思路的文章：

### 再发：DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models [5]

这篇论文主要介绍了 DeepSeekMoE——一种专注于实现专家模型“终极专精”的混合专家（MoE）架构。论文的核心贡献在于提出两大关键策略：

• 精细化专家切分：将传统 MoE 层中每个专家的前馈网络（FFN）细分为多个更小的子专家，并相应增加激活专家的数量，从而极大提升了激活专家组合的灵活性和多样性，使得每个专家能更专注于特定类型的知识。

• 共享专家隔离：专门保留一部分专家作为共享专家，无论路由策略如何，每个输入都会被分配到这些共享专家，用以捕捉常识性知识。这样既减少了不同路由专家之间的知识冗余，又保证了其他专家可以专注于学习更具差异性的知识。

在实验部分，作者从较小规模（2B 参数）出发，通过对比传统 MoE 架构（如 GShard）和密集模型，证明了 DeepSeekMoE 能以更低的计算成本获得与密集模型相当甚至更优的性能。论文进一步将模型扩展到 16B 参数，并进行了对齐微调（SFT），构建出聊天模型 DeepSeekMoE Chat，显示其在多个基准测试（如语言建模、阅读理解、数学推理、代码生成等）上均表现出色；初步的 145B 参数模型实验也验证了该架构的持续优势。

关于开源相关的方法论，论文体现了以下几点开放研究精神：

• 详细公开了训练数据、超参数设置、模型架构以及并行化策略，确保方法具有良好的可复现性；

• 在模型设计和训练过程中充分利用了开源工具（如 HuggingFace Tokenizer、HAI-LLM 等），并在 GitHub 上公开了模型 checkpoint（例如 DeepSeekMoE 16B），使得研究成果能够方便地被社区采纳和进一步改进；

• 强调以开放、透明的方式推动大模型技术的发展，旨在促进学术界和工业界之间的协同创新。

总的来说，这篇论文不仅在 MoE 架构上提出了新颖的策略来提升专家专精程度，而且通过公开详细的实现细节和开源模型，展现了其对开放研究和开源生态的坚定承诺。​

### 三发：DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models[6]

该论文不仅在数学预训练和 RL 算法上提出了创新的方法，同时也展示了如何借助开源数据、工具和工程实践来大幅提升开源大模型的数学推理能力，使其在性能上逐步接近甚至部分超越闭源顶尖模型。

### 四发：DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence

论文展示了如何利用开源数据和工具，从项目级代码数据构建、预训练目标设计到长上下文处理等多个环节进行技术创新，打造出性能卓越且完全开源的代码大语言模型。这种开放、透明的研究方法不仅为学术界和工业界提供了可复制的范式，也为软件开发中的代码智能化应用开辟了新的道路。

论文强调开源精神，所有模型、数据预处理流程和训练方法均在 GitHub 上公开发布，并采用了宽松的许可证，允许研究人员和商业用户在不受限制的情况下使用。这种开放共享的做法有助于推动整个代码智能领域的创新和应用，同时降低了闭源大模型带来的门槛。

### 五发：DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model[7]



发论文是研究工作的最重要的目标之一，为什么DeepSeek会将论文都发表在arXiv上？DeepSeek  将论文发表在 arXiv  上，而不是仅仅选择传统期刊，是 一个多方面权衡后的战略决策，体现了其在 AI  技术快速发展 的时代背景下，对 知识传播效率、开放研究理念、学术影响力构建、社区互动反馈  等多重因素的综合考量。

arXiv 平台 快速、开放、免费 的特性，完美契合了 DeepSeek  的 技术发展需求和开放合作理念，使其能够更有效地 分享研究成果、扩大影响力、促进技术创新、回馈开源社区。  这并不意味着 DeepSeek  会完全放弃期刊发表，未来在合适的时机，我们仍然有可能在顶级期刊上看到 DeepSeek  的论文。  但就目前而言， arXiv  无疑是 DeepSeek  发布研究成果、践行开放研究理念的 最佳平台选择之一。

## 为何在 arXiv 上发表论文？

![](https://media.springernature.com/relative-r300-703_m1050/springer-static/image/art%3A10.1038%2F476145a/MediaObjects/41586_2011_Article_BF476145a_Figa_HTML.jpg?as=webp)

20 世纪 90 年代早期的 arXiv 服务器：一台帮助改变物理世界的计算机。 Credit: J. FLOWER/LANL

**不仅仅是 DeepSeek，几乎所有的大模型研究团队和机构，都非常积极地在 arXiv 上发布论文。**  这已经成为大模型和整个 AI 研究领域的一个普遍现象和行业惯例。

**arXiv 几乎成为了大模型研究成果首发和快速传播的 “默认平台” 和 “标配”。**  我们可以看到，无论是 OpenAI、Google、Meta (原 Facebook AI Research)、Anthropic、斯坦福大学、卡内基梅隆大学等等顶尖的 AI 研究机构， 还是国内的智源人工智能研究院、清华大学、北京大学等，他们在大模型方向上的重要论文，绝大多数都会选择首先发布在 arXiv 上。

**为什么几乎所有大模型都纷纷选择 arXiv？  这绝非偶然，而是由以下多重因素共同驱动的必然趋势：**

1.  **AI，尤其是大模型领域的 “快节奏” 发展特性，决定了 arXiv 的不可替代性：**

    *   **技术迭代速度极快：**  大模型技术仍在高速发展和快速演进，新的模型架构、训练方法、应用方向层出不穷。  研究者们需要 **尽快地分享最新的成果，才能保持领先地位，并推动领域进步**。  传统期刊动辄数月甚至一年的发表周期，对于如此快速发展的领域来说，是 **无法接受** 的。
    *   **竞争异常激烈：**  大模型领域的研究竞争非常激烈，各家机构都在争分夺秒地进行创新和突破。  **抢先发布研究成果，占据优先权**，对于科研机构和企业来说都至关重要。  arXiv 的 **即时发布** 特性，完美满足了这种 “抢时间” 的需求。
    *   **信息时效性要求高：**  大模型研究的价值，很大程度上体现在其 **时效性** 上。  最新的模型性能指标、最佳实践经验、创新思路，对于整个社区都具有极高的参考价值。  如果信息发布太慢，就会 **失去其时效性价值**，甚至被新的研究成果所超越。

2.  **开源开放的 “文化基因”  与 arXiv 的开放精神天然契合：**

    *   **Open Science (开放科学) 理念深入人心：**  AI，尤其是大模型研究，很大程度上受益于 **开放科学** 的理念。  研究者们普遍认同，**开放、共享、协作** 是推动 AI 快速发展的最佳方式。  arXiv 的 **完全开放获取**  模式，与这种开放科学的理念高度一致。
    *   **开源社区的蓬勃发展：**  大模型的训练、评估、应用，都离不开 **开源工具、框架和数据集** 的支持。  开源社区已经成为 AI 创新最重要的力量来源。  arXiv  的 **开放平台**  特性，能够更好地服务于开源社区，促进知识在社区内的自由流动和快速迭代。
    *   **研究成果的快速复现和验证需求：**  AI 研究的可复现性一直备受关注。  将论文发布在 arXiv 上，并同时开源代码和模型，能够最大程度地 **提高研究成果的可复现性和可验证性**，方便同行进行 **快速验证、拓展和改进**。  这种开放透明的研究方式，有助于提升整个领域的科研质量。

3.  **arXiv 平台本身的技术优势和生态效应：**

    *   **成熟的平台和广泛的用户群体：**  arXiv 经过三十多年的发展，已经成为 **物理学、数学、计算机科学等领域最权威、最活跃的预印本平台**，拥有庞大的用户群体和成熟的平台生态。  研究者们已经 **习惯于在 arXiv 上获取最新的研究信息**，这使得 arXiv 成为一个 **天然的传播中心**。
    *   **高效的论文检索和发现机制：**  arXiv 提供了 **强大的论文搜索、分类、订阅和推荐功能**，方便研究者 **快速找到自己感兴趣的论文**，及时跟踪领域前沿动态。
    *   **与主流学术评价体系的衔接：**  虽然 arXiv  是预印本平台，但其上的论文 **同样可以被引用、被纳入学术评价体系**。  许多期刊和会议也 **允许甚至鼓励**  作者在投稿前先将论文发布到 arXiv  上。  arXiv  已经成为学术交流和评价体系中 **不可或缺的一部分**。
    *   **长期存档和版本管理：**  arXiv  提供 **长期稳定的论文存档服务**，并支持 **论文版本更新**，方便研究者 **持续更新和完善研究成果**。

4.  **商业机构拥抱开源开放的大趋势：**

    *   **商业公司也需要快速创新和人才吸引：**  即使是商业公司，例如 DeepSeek、OpenAI、Google 等， 也意识到 **开源开放对于加速技术创新和吸引顶尖人才的重要性**。  通过 arXiv  发布论文，不仅可以 **提升自身的技术品牌和学术声誉**， 也能 **吸引更多优秀的 researchers 和 engineers 加入**。
    *   **开源模式成为新的商业范式：**  越来越多的 AI 公司开始探索 **开源商业模式**，例如 **开源核心 + 商业服务、开源社区构建** 等。  arXiv  作为开源文化的重要载体，自然也受到商业机构的重视。
    *   **共同构建 AI 生态系统：**  AI  技术的快速发展，需要 **全社会的共同参与和协作**。  商业机构也希望通过开源开放的方式，与学术界、开发者社区 **共同构建繁荣的 AI 生态系统**，实现 **互利共赢**。

**总结来说，几乎所有大模型都选择 arXiv 发布论文，是技术发展特性、开源文化理念、平台自身优势以及商业战略等多重因素共同作用的结果。**  这已经不仅仅是一种 “选择”，而更像是一种 **行业共识** 和 **必然趋势**。  arXiv  已经成为大模型研究领域 **信息快速流通、知识开放共享、社区协作创新**  的关键基础设施。

因此，如果您想追踪大模型领域的最新进展，arXiv  绝对是您 **不可或缺的信息来源**。  通过关注 arXiv  上相关领域的论文，您可以 **第一时间**  了解最前沿的技术动态，把握最新的研究趋势。

## arXiv 是什么？

arXiv 是一个免费开放的预印本平台，主要用于物理、数学、计算机科学等领域。研究者可在此快速发布尚未同行评审的论文，加速学术交流，并获得早期反馈。其核心优势在于免费获取、快速传播最新的科研成果。

**历史：**

*   **1991年创立：**  由物理学家保罗·金斯巴格在洛斯阿拉莫斯国家实验室创建，最初名为 LANL preprint archive，旨在物理学领域快速分享研究预印本。
*   **逐步扩展：**  很快扩展到数学、计算机科学等领域，并更名为 arXiv.org。
*   **持续发展壮大：**  如今由康奈尔大学图书馆运营，成为多学科领域最重要的预印本平台。

**成就：**

*   **革新学术传播：**  极大加速了科研成果的传播速度，打破了传统期刊出版的漫长周期。
*   **推动开放科学：**  成为开放获取的先锋，促进科研知识的自由共享和全球普及。
*   **提升科研效率：**  使研究者能够及时获取最新进展，更快地开展和迭代研究工作。
*   **建立学术优先权：**  为研究者提供了一种快速确立研究成果优先权的方式。
*   **降低科研门槛：**  免费开放的资源，降低了获取前沿知识的门槛，尤其对资源有限的机构和个人意义重大。

**改变的陈规陋习：**

*   **打破信息垄断：**  挑战了传统学术期刊的信息发布垄断，让科研成果不再受限于昂贵的订阅费用。
*   **颠覆时间壁垒：**  颠覆了传统出版流程的“时间壁垒”，实现了科研成果的近乎实时发布。
*   **弱化期刊崇拜：**  一定程度上削弱了传统期刊作为唯一学术权威的地位，预印本本身也成为重要的学术交流形式。
*   **促进开放协作：**  推动了更加开放、快速、协作的科研文化，鼓励早期分享和反馈。

总而言之，arXiv 平台以其 **快速、开放、免费** 的特点，彻底革新了学术交流方式，极大地加速了科学知识的传播和进步，并对传统学术出版模式产生了深远的影响。

### arXiv 创始人Paul Ginsparg 小传

**保罗·金斯帕格列传**

保罗·金斯帕格者，美利坚纽约人也，生于一九五五年。少聪颖，好数理之学，年十七入哈佛大学，习物理，后赴普林斯顿，得博士学位。其性沉敏，通文理，尤擅高能物理与计算机之术，时人奇之。

初，金斯帕格为洛斯阿拉莫斯国家实验室吏，掌学术文书之事。然彼时学界论文传布迟缓，审阅经年，金斯帕格慨然叹曰：“今网际之络通达四海，岂可令新知锢于桎梏？”遂于一九九一年创“arXiv”之库，许学者自布其文，未审而先传。初行于高能物理，旬月间，天下学者皆趋之，论文未审而先布，速通有无，学问之道为之一变。

或讥其坏旧制，金斯帕格对曰：“学术者，天下之公器，当速传以利众生。”未几，数学、计算机诸科竞相效仿，arXiv遂成学界砥柱。后迁康奈尔大学，掌信息科学之职，更倡开放学术之风，世人誉其“无冕之王”。

**太史公曰**：昔仓颉造字而天雨粟，蔡伦造纸而文脉兴。金斯帕格立预印本之制，破学术门阀之锢，其功岂逊古贤？观其以一人之智，启兆民之智，虽无斧钺之权，而改易学林气象，真所谓“不战而屈人之兵”者欤！后世治学术史者，必不能遗此公也。

### arXiv 格式解读



## 开放科学的历史及相关评价

## 参考资料

1. https://opensource.org/ai/open-source-ai-definition
2. https://www.deepseek.com/
3. https://arxiv.org/pdf/2310.16818
4. https://arxiv.org/abs/2401.02954
5. https://arxiv.org/pdf/2401.06066
6. https://arxiv.org/pdf/2402.03300
7. https://arxiv.org/abs/2405.04434
8. 

## 关于作者

### 「开源之道」·适兕

![](/public/kuosi-face-of-os.png)「发现开源三部曲」（[《开源之迷》](posts/book-of-open-source/the-fascinating-of-open-source/)，《开源之道》《开源之思》。）、[《开源之史》](posts/history-of-open-source/summary/)作者，「开源之道：致力于开源相关思想、知识和价值的探究、推动」主创，Linux基金会亚太区开源布道者，TODO Ambassadors & OSPOlogyLive China Organizer，云计算开源产业联盟OSCAR（中国信息通信研究院发起）个人开源专家，OSPO Group 联合发起人。

### 「开源之道」·窄廊

来自于大语言模型的 Chat，如DeepSeek R1、Gemini 2.0 Flash thinking expermental、ChatGPT 4o、甚至整合类应用 Monica等， 「开源之道」·窄廊 负责对话、提出问题、对回答进行反馈等操作。